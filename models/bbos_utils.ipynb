{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import *\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_bbox(ellipse: Tensor) -> Tensor:\n",
    "    \"\"\"Convert an ellipse to a corner to corner rectangle.\"\"\"\n",
    "\n",
    "    if ellipse.ndim == 1:\n",
    "        cos, sin = torch.cos, torch.sin\n",
    "        a, b, theta, x, y = ellipse\n",
    "        ta = a * cos(theta)\n",
    "        tb = b * sin(theta)\n",
    "        tc = a * sin(theta)\n",
    "        td = b * cos(theta)\n",
    "        dx = (ta**2 + tb**2) ** 0.5\n",
    "        dy = (tc**2 + td**2) ** 0.5\n",
    "        return torch.tensor([x - dx, y - dy, x + dx, y + dy])\n",
    "    else:\n",
    "        # last dimension is eclipse\n",
    "        return torch.stack([ellipse_bbox(e) for e in ellipse[..., :]]).reshape(\n",
    "            ellipse.shape[:-1] + (4,)\n",
    "        )\n",
    "\n",
    "\n",
    "def tensor_ellipse(ellipse: Tensor, color: str = \"r\") -> mpl.patches.Ellipse:\n",
    "    \"\"\"Convert an ellipse to a matplotlib ellipse.\"\"\"\n",
    "\n",
    "    if ellipse.ndim == 1:\n",
    "        a, b, theta, x, y = ellipse\n",
    "        return mpl.patches.Ellipse(\n",
    "            (x, y),\n",
    "            a * 2,\n",
    "            b * 2,\n",
    "            angle=theta / math.pi * 180,\n",
    "            fill=False,\n",
    "            linewidth=1,\n",
    "            edgecolor=color,\n",
    "        )\n",
    "    else:\n",
    "        # last dimension is eclipse\n",
    "        return mpl.collections.PatchCollection(\n",
    "            [tensor_ellipse(e, color) for e in ellipse[..., :]],\n",
    "            match_original=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_rect(bbox: Tensor, color: str = \"r\") -> mpl.patches.Rectangle:\n",
    "    \"\"\"Convert a bounding box to a matplotlib rectangle.\"\"\"\n",
    "\n",
    "    return mpl.patches.Rectangle(\n",
    "        (bbox[0], bbox[1]),\n",
    "        bbox[2] - bbox[0],\n",
    "        bbox[3] - bbox[1],\n",
    "        linewidth=1,\n",
    "        fill=False,\n",
    "        edgecolor=color,\n",
    "    )\n",
    "\n",
    "\n",
    "def _ensure_ax(ax: Optional[plt.Axes] = None) -> plt.Axes:\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def show_bbox(\n",
    "    bbox: Tensor,\n",
    "    ax: Optional[plt.Axes] = None,\n",
    "    color: Union[str, Iterable[str]] = \"r\",\n",
    "    label: Optional[Iterable[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot bounding box(s) on the image.\"\"\"\n",
    "\n",
    "    if bbox.ndim == 1:\n",
    "        bbox = bbox[None, ...]\n",
    "    if not isinstance(color, list | Tensor | np.ndarray):\n",
    "        color = [color] * len(bbox)\n",
    "\n",
    "    if label is None:\n",
    "        label = [\"\"] * len(bbox)\n",
    "    elif not isinstance(label, list):\n",
    "        label = list(label)\n",
    "\n",
    "    ax = _ensure_ax(ax)\n",
    "    try:\n",
    "        for b, c, l in zip(bbox, color, label, strict=True):\n",
    "            ax.add_patch(tensor_rect(b, c))\n",
    "            ax.text(b[0], b[1], l, color=c)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            \"The number of labels (colors) must be the same as the number of bounding boxes.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def show_ellipse(\n",
    "    ellipse: Tensor, ax: Optional[plt.Axes] = None, color: str = \"r\"\n",
    ") -> None:\n",
    "    \"\"\"Plot an ellipse on the image.\"\"\"\n",
    "\n",
    "    if ellipse.ndim == 1:\n",
    "        ellipse = ellipse[None, ...]\n",
    "    ax = _ensure_ax(ax)\n",
    "    for e in ellipse:\n",
    "        ax.add_patch(tensor_ellipse(e, color=color))\n",
    "\n",
    "\n",
    "def show_image(image: Tensor | Image.Image, ax: plt.Axes = None):\n",
    "    \"\"\"Show an image.\"\"\"\n",
    "\n",
    "    ax = _ensure_ax(ax)\n",
    "    if isinstance(image, Tensor):\n",
    "        image = transforms.ToPILImage()(image)\n",
    "    ax.imshow(image)\n",
    "    ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_draw():\n",
    "    box = tensor([0.5, 0.5, 1.0, 1.0])\n",
    "    ellipse = tensor([0.5, 0.5, 0.0, 0.5, 0.5])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    show_image(torch.rand(3, 5, 5), ax=ax)\n",
    "    show_bbox(box, ax=ax)\n",
    "    show_ellipse(ellipse, ax=ax)\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "def test_batch_draw():\n",
    "    boxes = tensor([[0.5, 0.5, 1.0, 1.0], [1.0, 1.0, 2.0, 2.0]])\n",
    "    ellipses = tensor(\n",
    "        [[2, 1, math.pi / 3, 1, 1], [1.0, 2.0, math.pi / 3, 1.0, 1.0]],\n",
    "    )  # oblique ecllipse works\n",
    "    ellipse_bboxes = ellipse_bbox(ellipses)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    show_image(torch.rand(3, 5, 5), ax=ax)\n",
    "    show_bbox(boxes, ax=ax)\n",
    "    show_bbox(ellipse_bboxes, ax=ax, color=\"w\")\n",
    "    show_ellipse(ellipses, ax=ax, color=\"b\")\n",
    "    ax.set_aspect(\"equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_corner2center(bbox: Tensor) -> Tensor:\n",
    "    \"\"\"Convert a corner to corner bounding box to a center to corner bounding box.\"\"\"\n",
    "\n",
    "    return torch.stack(\n",
    "        [\n",
    "            (bbox[..., 0] + bbox[..., 2]) / 2,\n",
    "            (bbox[..., 1] + bbox[..., 3]) / 2,\n",
    "            bbox[..., 2] - bbox[..., 0],\n",
    "            bbox[..., 3] - bbox[..., 1],\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "def bbox_center2corner(bbox: Tensor) -> Tensor:\n",
    "    \"\"\"Convert a center to corner bounding box to a corner to corner bounding box.\"\"\"\n",
    "\n",
    "    return torch.stack(\n",
    "        [\n",
    "            bbox[..., 0] - bbox[..., 2] / 2,\n",
    "            bbox[..., 1] - bbox[..., 3] / 2,\n",
    "            bbox[..., 0] + bbox[..., 2] / 2,\n",
    "            bbox[..., 1] + bbox[..., 3] / 2,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "def bbox_corner_width2corner(bbox: Tensor) -> Tensor:\n",
    "    \"\"\"Convert a corner to width bounding box to a corner to corner bounding box.\"\"\"\n",
    "\n",
    "    return torch.stack(\n",
    "        [\n",
    "            bbox[..., 0],\n",
    "            bbox[..., 1],\n",
    "            bbox[..., 0] + bbox[..., 2],\n",
    "            bbox[..., 1] + bbox[..., 3],\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bbox_conversion():\n",
    "    bbox = torch.rand(10, 4)\n",
    "    assert torch.allclose(bbox, bbox_center2corner(bbox_corner2center(bbox)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchors(data, sizes, ratios) -> Tensor:\n",
    "    \"\"\"Generate anchors for each pixel of the image in the data. For each\n",
    "    pixel, (sizes[0], ratios) + (ratios[0], sizes) are generated. Notice the\n",
    "    duplicated (sizes[0], ratios[0]) will be removed.\n",
    "\n",
    "    The result will be a tensor of shape (1, (len(sizes) + len(ratios) - 1) * width * height, 4)\"\"\"\n",
    "\n",
    "    width, height = data.shape[-2:]\n",
    "    n_sizes, n_ratios = len(sizes), len(ratios)\n",
    "    boxes_per_pixel = n_sizes + n_ratios - 1\n",
    "\n",
    "    device = data.device\n",
    "    sizes = torch.tensor(sizes, device=device)\n",
    "    ratios = torch.tensor(ratios, device=device)\n",
    "\n",
    "    center_h, center_w = [\n",
    "        s * (torch.arange(0, n, device=device) + 0.5)\n",
    "        for n, s in zip((height, width), (1 / height, 1 / width))\n",
    "    ]\n",
    "    center_w, center_h = [\n",
    "        c.flatten() for c in torch.meshgrid(center_w, center_h, indexing=\"ij\")\n",
    "    ]\n",
    "    w = (\n",
    "        torch.cat(\n",
    "            (\n",
    "                sizes * torch.sqrt(ratios[0]),\n",
    "                sizes[0] * torch.sqrt(ratios[1:]),\n",
    "            )\n",
    "        )\n",
    "        * height\n",
    "        / width\n",
    "    )\n",
    "    h = torch.cat(\n",
    "        (\n",
    "            sizes / torch.sqrt(ratios[0]),\n",
    "            sizes[0] / torch.sqrt(ratios[1:]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    anchors = torch.stack((-w, -h, w, h)).T.repeat(height * width, 1) / 2\n",
    "    return (\n",
    "        torch.stack((center_w, center_h, center_w, center_h), dim=1).repeat_interleave(\n",
    "            boxes_per_pixel, dim=0\n",
    "        )\n",
    "        + anchors\n",
    "    ).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_anchors():\n",
    "    data = torch.rand(2, 3, 5, 5)\n",
    "    sizes = [0.1, 0.2]\n",
    "    ratios = [0.5, 1.0, 2.0]\n",
    "    assert anchors(data, sizes, ratios).shape == (\n",
    "        2, # batch size\n",
    "        5 * 5 * 4, # bpp * pixels\n",
    "        4, # 4\n",
    "    )  # channels doesn't matter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_scale(bbox: Tensor, image: Tensor | Image.Image):\n",
    "    \"\"\"Scale a bounding box to the size of the image.\"\"\"\n",
    "\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = transforms.ToTensor()(image)\n",
    "    return bbox * torch.tensor(image.shape[-2:]).flip(0).repeat(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scale_bbox():\n",
    "    image = torch.rand(3, 5, 5)\n",
    "    bbox = torch.rand(2, 4)\n",
    "    assert torch.allclose(bbox_scale(image, bbox), bbox * 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_area(box: Tensor) -> Tensor:\n",
    "    \"\"\"Compute the area of a bounding box.\"\"\"\n",
    "\n",
    "    return (box[..., 2] - box[..., 0]) * (box[..., 3] - box[..., 1])\n",
    "\n",
    "\n",
    "def iou(a: Tensor, b: Tensor) -> Tensor:\n",
    "    \"\"\"Calculate the intersection over union (Jaccard Coefficient) of 2 bboxes\"\"\"\n",
    "\n",
    "    aa, ab = box_area(a), box_area(b)\n",
    "    # upper left corner (in cartesian plane, where y increases downward (as in image))\n",
    "    inter_ul = torch.max(a[..., :2], b[..., :2])\n",
    "    # lower right corner\n",
    "    inter_lr = torch.min(a[..., 2:], b[..., 2:])\n",
    "    inter = (inter_lr - inter_ul).clamp(min=0)\n",
    "    inter_area = inter[..., 0] * inter[..., 1]\n",
    "    # 𝐉(a, b) = a ∩ b / a ∪ b\n",
    "    union_area = aa + ab - inter_area\n",
    "    return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_iou():\n",
    "    a = torch.tensor([[0, 0, 1, 1], [0, 0, 2, 2]])\n",
    "    b = torch.tensor([[0, 0, 1, 1], [0, 0, 1, 1]])\n",
    "    assert torch.allclose(iou(a, b), torch.tensor([1.0, 0.25]))\n",
    "    a = torch.tensor([[[0, 0, 1, 1], [0, 0, 2, 2]], [[0, 0, 1, 1], [0, 0, 1, 1]]])\n",
    "    b = torch.tensor([[[0, 0, 1, 1], [0, 0, 1, 1]], [[0, 0, 1, 1], [0, 0, 1, 1]]])\n",
    "    assert torch.allclose(iou(a, b), torch.tensor([[1.0, 0.25], [1.0, 1.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_gt(anchors: Tensor, gts: Tensor, iou_threshold: float = 0.5) -> Tensor:\n",
    "    \"\"\"Assign ground truth to each bounding box. If a bounding box has an\n",
    "    intersection over union with a ground truth greater than iou_threshold,\n",
    "    then the ground truth is assigned to the bounding box. Otherwise, the\n",
    "    bounding box is assigned to the background class.\"\"\"\n",
    "\n",
    "    ious = iou(anchors.unsqueeze(1), gts.unsqueeze(0))\n",
    "    anchor2gt = torch.full((len(anchors),), -1)\n",
    "\n",
    "    max_ious, max_ious_idxs = ious.max(dim=1)\n",
    "    anchor_idxs = torch.nonzero(max_ious >= iou_threshold).flatten()\n",
    "    gt_idxs = max_ious_idxs[max_ious >= iou_threshold]\n",
    "    anchor2gt[anchor_idxs] = gt_idxs\n",
    "\n",
    "    for _ in range(len(gts)):\n",
    "        max_idx = ious.argmax()\n",
    "        anchor_idx, gt_idx = torch.div(\n",
    "            max_idx, len(gts), rounding_mode=\"trunc\"\n",
    "        ), max_idx % len(gts)\n",
    "        anchor2gt[anchor_idx] = gt_idx\n",
    "        ious[anchor_idx, :] = ious[:, gt_idx] = -1\n",
    "    return anchor2gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_assign_gt():\n",
    "    anchors = torch.tensor([[0, 0, 1, 1], [0, 0, 2, 2]])\n",
    "    gts = torch.tensor([[0, 0, 1, 1], [0, 0, 1, 1]])\n",
    "    assert torch.allclose(assign_gt(anchors, gts), torch.tensor([0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_offset(anchors, gts, eps=1.0e-6):\n",
    "    \"\"\"Calculate the offset between the anchors and the ground truth bounding\n",
    "    boxes.\"\"\"\n",
    "\n",
    "    anchors = bbox_corner2center(anchors)\n",
    "    gts = bbox_corner2center(gts)\n",
    "    wh = anchors[..., 2:]\n",
    "    oxy = 10 * (gts[..., :2] - anchors[..., :2]) / wh\n",
    "    owh = 5 * torch.log(eps + gts[..., 2:] / wh)\n",
    "    return torch.cat((oxy, owh), axis=-1)\n",
    "\n",
    "\n",
    "def bbox_recover(anchors, offsets):\n",
    "    \"\"\"Recover the bounding box from the offset.\"\"\"\n",
    "\n",
    "    anchors = bbox_corner2center(anchors)\n",
    "    wh = anchors[..., 2:]\n",
    "    oxy = offsets[..., :2] / 10 * wh + anchors[..., :2]\n",
    "    owh = torch.exp(offsets[..., 2:] / 5) * wh\n",
    "    return bbox_center2corner(torch.cat((oxy, owh), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bbox_recover():\n",
    "    anchors = torch.tensor([[0, 0, 1, 1], [0, 0, 2, 2]], dtype=torch.float32)\n",
    "    offsets = torch.tensor([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "    assert torch.allclose(bbox_recover(anchors, offsets), anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(anchors, labels):\n",
    "    \"\"\"Assign labels to anchors. For anchors that are not assigned to a\n",
    "    ground truth, they are assigned to the background class.\n",
    "\n",
    "    :param anchors: (batch_size)? x num_anchors x 4\n",
    "    :param labels: (batch_size)? x num_anchors x 5\n",
    "        where the last dimension is (class, bbox)\n",
    "        \n",
    "    :return: (\n",
    "        offset: (batch_size)? x num_anchors x 4,\n",
    "        mask: (batch_size)? x num_anchors x 4, where background class is 0\n",
    "        classes: (batch_size)? x num_anchors, where 0 is the background class\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    if labels.ndim > 2:\n",
    "        return (\n",
    "            torch.stack(x)\n",
    "            for x in zip(*[assign_label(anchors, label) for label in labels])\n",
    "        )\n",
    "\n",
    "    anchors2gt = assign_gt(anchors, labels[..., 1:])  # first column is class\n",
    "    not_bg = anchors2gt >= 0\n",
    "    masks = not_bg.float().unsqueeze(-1).repeat(1, 4)\n",
    "\n",
    "    classes = torch.full((len(anchors),), 0)\n",
    "    classes[not_bg] = labels[anchors2gt[not_bg], 0].long() + 1\n",
    "\n",
    "    anchors2bbox = torch.zeros((len(anchors), 4))\n",
    "    anchors2bbox[not_bg] = labels[anchors2gt[not_bg], 1:].float()\n",
    "\n",
    "    offsets = bbox_offset(anchors, anchors2bbox) * masks\n",
    "    return (offsets, masks, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(bboxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"Non-maximum suppression.\n",
    "    \n",
    "    :param bboxes: (batch_size)? x num_bboxes x 4\n",
    "    :param scores: (batch_size)? x num_bboxes\n",
    "    :param iou_threshold: the threshold for the intersection over union\n",
    "\n",
    "    :return: (batch_size)? x indices of bboxes that are not suppressed\n",
    "    \"\"\"\n",
    "\n",
    "    idxs = scores.argsort(descending=True, dim=-1)\n",
    "    keep = []\n",
    "    while len(idxs) > 0:\n",
    "        keep.append(idxs[0])\n",
    "        if len(idxs) == 1:\n",
    "            break\n",
    "        ious = iou(bboxes[idxs[0]].unsqueeze(0), bboxes[idxs[1:]])\n",
    "        idxs = idxs[1:][ious <= iou_threshold]\n",
    "    return torch.tensor(keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(anchors, cls_probs, offsets, confidence_threshold=0.01, nms_threshold=0.5):\n",
    "    \"\"\"Give anchors, class probabilities, and offsets, return the bounding\n",
    "    boxes, their class probabilities, and their class labels. Further, apply\n",
    "    non-maximum suppression to the bounding boxes.\n",
    "\n",
    "    :param anchors: (batch size)? x (number of anchors) x 4\n",
    "    :param cls_probs: (batch size)? x (number of classes) x (number of anchors)\n",
    "    :offsets: (batch size)? x (number of anchors) x 4\n",
    "    :return: (batch size)? x (number of bounding boxes) x 6, where\n",
    "        the last dimension is (class label, class probability/confidence, bounding box)\n",
    "    \"\"\"\n",
    "\n",
    "    if cls_probs.ndim > 2 and offsets.ndim > 2:  # support batched inputs\n",
    "        return (\n",
    "            torch.stack(x)\n",
    "            for x in zip(\n",
    "                *[\n",
    "                    detect(anchors, cls_prob, offset)\n",
    "                    for cls_prob, offset in zip(cls_probs, offsets)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    confidence, anchor_idxs = cls_probs.max(\n",
    "        dim=-2\n",
    "    )  # operate on the columns, i.e., anchors\n",
    "    predict_bboxes = bbox_recover(anchors, offsets)\n",
    "    keep = nms(predict_bboxes, confidence, nms_threshold)\n",
    "\n",
    "    # set background class to -1 (not in keep or confidence < confidence_threshold)\n",
    "    anchor_idxs[\n",
    "        torch.cat((keep, torch.arange(len(anchors))),).unique(\n",
    "            return_counts=True\n",
    "        )[1]\n",
    "        == 1\n",
    "    ] = -1\n",
    "    anchor_idxs[confidence < confidence_threshold] = -1\n",
    "\n",
    "    return torch.cat(\n",
    "        (\n",
    "            anchor_idxs.unsqueeze(-1),\n",
    "            confidence.unsqueeze(-1),\n",
    "            predict_bboxes,\n",
    "        ),\n",
    "        axis=-1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_detect():\n",
    "    anchors = torch.tensor(\n",
    "        [[0, 0, 1, 1], [0, 0, 2, 2], [0, 0, 3, 3]], dtype=torch.float32\n",
    "    )\n",
    "    cls_probs = torch.tensor([[0, 0, 0], [0.1, 0.9, 0], [0.9, 0.1, 0]])\n",
    "    offsets = torch.zeros((3, 4))\n",
    "    assert torch.allclose(\n",
    "        detect(anchors, cls_probs, offsets),\n",
    "        torch.tensor(\n",
    "            [\n",
    "                [2, 0.9, 0, 0, 1, 1],\n",
    "                [1, 0.9, 0, 0, 2, 2],\n",
    "                [-1, 0.0, 0, 0, 3, 3], # background class\n",
    "            ]\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(img, results, class_names: list[str], ax: Optional[plt.Axes] = None):\n",
    "    \"\"\"\n",
    "    Show the detection results.\n",
    "\n",
    "    :param img: (height, width, 3)\n",
    "    :param results: (number of bounding boxes) x 6, where the last dimension\n",
    "        is (class label, confidence, bounding box)\n",
    "    :param class_names: list of classes\n",
    "    :param ax: the axes to use to plot\n",
    "    \"\"\"\n",
    "\n",
    "    ax = _ensure_ax(ax)\n",
    "    show_image(img, ax=ax)\n",
    "    color_map = dict(\n",
    "        zip(\n",
    "            class_names,\n",
    "            cmap(np.linspace(0, 1, len(class_names) + 1)),\n",
    "        )\n",
    "    )\n",
    "    class_names.insert(0, \"background\")\n",
    "    results = results[results[:, 0] > 0]\n",
    "\n",
    "    labels = [\n",
    "        f\"{class_names[int(result[0])]}: {result[1]:.2f}\"\n",
    "        for result in results\n",
    "    ]\n",
    "    colors = [color_map[class_names[int(result[0])]] for result in results]\n",
    "    bboxes = results[:, 2:]\n",
    "    bboxes = bbox_scale(bboxes, img)\n",
    "\n",
    "    show_bbox(\n",
    "        bboxes,\n",
    "        label=labels,\n",
    "        color=colors,\n",
    "        ax=ax,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a06eea670a17a68af0bc4f7efd325940a1dd9fb389e82d76b6d88de861831d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
